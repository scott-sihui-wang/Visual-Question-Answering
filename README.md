# Visual Question Answering

## 1. Introduction

### 1.1 Background and Motivation

Reasoning about everyday visual input is one of the most fundamental building blocks of human intelligence. `Visual Question Answering` (VQA) is a rapidly evolving field which witnesses many achievements, however, it is unclear if the models get good performance on certain dataset because of true reasoning abilities or just overfitting to biases in the datasets.

### 1.2 Tasks of the Project



**Topics:** _Visual Question Answering_, _Grounded Natural Language Processing_

**Skills:** _Pytorch_, _Python_, _Deep Neural Networks_

## 2. Results

## 3. Acknowledgement

We acknowledge the use of codes from [PG+EE](https://github.com/facebookresearch/clevr-iep) and [NS-VQA](https://github.com/kexinyi/ns-vqa).
